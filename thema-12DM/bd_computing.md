# Module: Big data computing

| Gegevensveld  | Waarde |
| ------------- | ------------- |
| Osiriscode  | BFVH4BDC  |
| ECTS  | 3 |
| Toetsvorm  | Opdracht|
| Minimum cijfer  | 5,5 |
| Docent(en)  | HEMI|
| Contactpersoon  |  HEMI|
| Voertaal  | Nederlands |

## Cursusdoelen (leerdoelen)

- Kennis opdoen van bestaande grid-computing systemen.
- Leren programmeren met de Spark API (Java/Python).
- Leren hoe bestaande programmaâ€™s en algoritmen aan te passen voor gebruik met Spark.
- Leren beredeneren welke parallelisatiestrategie het beste voor een bepaalde dataset of algoritme werkt
- Begrijpen hoe grafische of andere customhardware Deep Learning versnelt
- De TensorFlow toolkit voor deep learning kennen en kunnen toepassen op een biologisch relevant deep learning probleem

## Inhoud

Bioinformatici moeten bijzonder grote hoeveelheden data kunnen verwerken; gigabytes zo niet terabytes. Individuele computers zijn hier vaak niet krachtig genoeg voor.

Een oplossing is dan om meerdere computers aan het rekenen te zetten.
Hoe dit te organiseren is een zich continu ontwikkelend veld. In dit vak komt de theorie van een aantal verschillende systemen aan bod (OpenMPI, Condor, SLURM, Hadoop, Spark), en wordt de focus gelegd op het Spark systeem. Daarnaast vragen veel van deze systemen, en Spark in het bijzonder, een bepaalde organisatie van de data die verwerkt moet worden: een gedistribueerde database zoals HDFS, Cassandra of Spark DataFrames.
Dit Grid-computing systeem is erg populair in de "Big Data" wereld maar vergt wel aanpassing van bestaande programma's naar een bepaald format: het Map/Reduce patroon. Aan de hand van de Weka toolkit uit de module Advanced Datamining worden een aantal algoritmen uit Thema 11 aangepast voor Spark.
De geleerde technieken zullen verder toegepast worden in het project van Thema 12 "Big Data & Machine Learning". Online documentatie op http://hadoop.apache.org/ en andere webstes van de gebruikte software: URLs hiervoor zijn te vinden op BlackBoard en in het dictaat voor dit vak.

Een andere manier om grote hoeveelheden data te verwerken, en dan in het bijzonder om machine learning met "Deep Learning" algoritmen erop toe te passen is om deze berekeningen op grafische hardware of andere in Lineaire Algebra gespecialiseerde hardware te draaien. Om dit concept toe te lichten wordt Google's TensorFlow deep learning toolkit geintroduceerd.

Dit vak bestaat uit korte introductie hoorcolleges, waarna praktisch gewerkt wordt aan opdrachten die de verschillende technieken en softwarepakketten gebruiken. Deze opdrachten worden op correctheid en snelheid getoetst en vormen samen de beoordeling van het vak. Een opdracht missen is een onvoldoende halen!
### Literatuur en andere bronnen

**Literatuur**  
- Cursus collegesheets en dictaat
Eventueel:
- Learning Tensorflow, Tom Hope, Yehezkel Resheff & Itay Lieder, ISBN  978-1491978511
- Spark: The Definitive Guide: Big Data Processing Made Simple, Matei Zaharia & Bill Chambers, ISBN 978-1491912218

**Web**
- Blackboard course thema 12 (Datamining)

### Competenties
\-

### Werkvormen  

- Hoor/werkcolleges

#### Ingangseisen 
\- 

#### Ingangseisen toets
\- 

#### Voorkennis
- Goede kennis van programmeren, in Java en/of Python, wordt verondersteld
- Kennis van basale algoritmiek zoals in Algoritmen en Datastructuren wordt verondersteld
- Kennis van Linux/command line gebruik wordt verondersteld

#### Voorkennis kan worden opgedaan met
- Informatica 1-3, Intro Java, Algoritmen en Datastructuren, Linuxcursus Thema 4

#### Bronnen van zelfstudie
\-

#### Verplicht materiaal
- geen

#### Aanbevolen materiaal
- collegesheets, dictaat, achtergrond websites/documentatie van de gebuikte software

